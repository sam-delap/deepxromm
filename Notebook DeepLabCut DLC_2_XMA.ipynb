{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f7f6696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc10...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rober\\anaconda3\\envs\\DEEPLABCUT\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "import os\n",
    "import imageio\n",
    "import imageio.v3 as iio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68efd3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bodyparts_from_xma(csv_path: str,\n",
    "                            mode: str):\n",
    "    \"\"\"Takes the filepath of an XMAlab CSV file and returns marker names\"\"\"\n",
    "\n",
    "    trial_csv = pd.read_csv(\n",
    "        csv_path,\n",
    "        sep=\",\",\n",
    "        header=0,\n",
    "        dtype=\"float\",\n",
    "        na_values=\"NaN\",\n",
    "    )\n",
    "    names = trial_csv.columns.values\n",
    "    if mode == \"rgb\":\n",
    "        parts = [name.rsplit(\"_\", 1)[0] for name in names]\n",
    "    elif mode in [\"2D\", \"per_cam\"]:\n",
    "        parts = [name.rsplit(\"_\", 2)[0] for name in names]\n",
    "    else:\n",
    "        raise SyntaxError(\"Invalid value for mode parameter\")\n",
    "\n",
    "    # I do it this way to maintain ordering in the list, since that's\n",
    "    # important for DeepLabCut\n",
    "    parts_unique = []\n",
    "    for part in parts:\n",
    "        if part not in parts_unique:\n",
    "            parts_unique.append(part)\n",
    "    return parts_unique\n",
    "\n",
    "def _splice_xma_to_dlc(self, trial_path, outlier_mode=False):\n",
    "    \"\"\"Takes csv of XMALab 2D XY coordinates from 2 cameras, outputs spliced hdf+csv data for DeepLabCut\"\"\"\n",
    "    substitute_data_relpath = \"labeled-data/\" + self._config[\"dataset_name\"]\n",
    "    substitute_data_abspath = os.path.join(\n",
    "        os.path.sep.join(self._config[\"path_config_file\"].split(\"\\\\\")[:-1]),\n",
    "        substitute_data_relpath,\n",
    "    )\n",
    "    trial_csv_path = self.find_trial_csv(trial_path)\n",
    "    markers = self.get_bodyparts_from_xma(trial_csv_path, mode='2D')\n",
    "\n",
    "    # TODO: this entire section can be solved with a creative call to\n",
    "    # get_bodyparts_from_xma and some dataFrame manipulation to be\n",
    "    # significantly shorter (and potentially faster?)\n",
    "    try:\n",
    "        trial_name = os.path.basename(os.path.normpath(trial_path))\n",
    "        df = pd.read_csv(f\"{trial_path}/{trial_name}.csv\")\n",
    "    except FileNotFoundError as e:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Please make sure that your trainingdata 2DPoints csv file is named {trial_name}.csv\"\n",
    "        ) from e\n",
    "    if self._swap_markers:\n",
    "        print(\"Creating cam1Y-cam2Y-swapped synthetic markers\")\n",
    "        swaps = []\n",
    "        df_sw = pd.DataFrame()\n",
    "        for marker in markers:\n",
    "            name_x1 = marker + \"_cam1_X\"\n",
    "            name_x2 = marker + \"_cam2_X\"\n",
    "            name_y1 = marker + \"_cam1_Y\"\n",
    "            name_y2 = marker + \"_cam2_Y\"\n",
    "            swap_name_x1 = \"sw_\" + name_x1\n",
    "            swap_name_x2 = \"sw_\" + name_x2\n",
    "            swap_name_y1 = \"sw_\" + name_y1\n",
    "            swap_name_y2 = \"sw_\" + name_y2\n",
    "            df_sw[swap_name_x1] = df[name_x1]\n",
    "            df_sw[swap_name_y1] = df[name_y2]\n",
    "            df_sw[swap_name_x2] = df[name_x2]\n",
    "            df_sw[swap_name_y2] = df[name_y1]\n",
    "            swaps.extend([swap_name_x1, swap_name_y1, swap_name_x2, swap_name_y2])\n",
    "        df = df.join(df_sw)\n",
    "        print(swaps)\n",
    "    if self._cross_markers:\n",
    "        print(\"Creating cam1-cam2-crossed synthetic markers\")\n",
    "        crosses = []\n",
    "        df_cx = pd.DataFrame()\n",
    "        for marker in markers:\n",
    "            name_x1 = marker + \"_cam1_X\"\n",
    "            name_x2 = marker + \"_cam2_X\"\n",
    "            name_y1 = marker + \"_cam1_Y\"\n",
    "            name_y2 = marker + \"_cam2_Y\"\n",
    "            cross_name_x = \"cx_\" + marker + \"_cam1x2_X\"\n",
    "            cross_name_y = \"cx_\" + marker + \"_cam1x2_Y\"\n",
    "            df_cx[cross_name_x] = df[name_x1] * df[name_x2]\n",
    "            df_cx[cross_name_y] = df[name_y1] * df[name_y2]\n",
    "            crosses.extend([cross_name_x, cross_name_y])\n",
    "        df = df.join(df_cx)\n",
    "        print(crosses)\n",
    "    names_final = df.columns.values\n",
    "    parts_final = [name.rsplit(\"_\", 1)[0] for name in names_final]\n",
    "    parts_unique_final = []\n",
    "    for part in parts_final:\n",
    "        if not part in parts_unique_final:\n",
    "            parts_unique_final.append(part)\n",
    "    print(\"Importing markers: \")\n",
    "    print(parts_unique_final)\n",
    "    with open(self._config[\"path_config_file\"], \"r\") as dlc_config:\n",
    "        yaml = YAML()\n",
    "        dlc_proj = yaml.load(dlc_config)\n",
    "\n",
    "    dlc_proj[\"bodyparts\"] = parts_unique_final\n",
    "\n",
    "    with open(self._config[\"path_config_file\"], \"w\") as dlc_config:\n",
    "        yaml.dump(dlc_proj, dlc_config)\n",
    "\n",
    "    df = df.dropna(how=\"all\")\n",
    "    list_of_frames = df.index + 1\n",
    "    unique_frames_set = set(list_of_frames)\n",
    "    unique_frames = sorted(unique_frames_set)\n",
    "    print(\"Importing frames: \")\n",
    "    print(unique_frames)\n",
    "    df[\"frame_index\"] = [\n",
    "        substitute_data_relpath\n",
    "        + f\"/{trial_name}_rgb_\"\n",
    "        + str(index).zfill(4)\n",
    "        + \".png\"\n",
    "        for index in unique_frames\n",
    "    ]\n",
    "    df[\"scorer\"] = self._config[\"experimenter\"]\n",
    "    df = df.melt(id_vars=[\"frame_index\", \"scorer\"])\n",
    "    new = df[\"variable\"].str.rsplit(\"_\", n=1, expand=True)\n",
    "    df[\"variable\"], df[\"coords\"] = new[0], new[1]\n",
    "    df = df.rename(columns={\"variable\": \"bodyparts\"})\n",
    "    df[\"coords\"] = df[\"coords\"].str.rstrip(\" \").str.lower()\n",
    "    cat_type = pd.api.types.CategoricalDtype(\n",
    "        categories=parts_unique_final, ordered=True\n",
    "    )\n",
    "    df[\"bodyparts\"] = df[\"bodyparts\"].str.lstrip(\" \").astype(cat_type)\n",
    "    newdf = df.pivot_table(\n",
    "        columns=[\"scorer\", \"bodyparts\", \"coords\"],\n",
    "        index=\"frame_index\",\n",
    "        values=\"value\",\n",
    "        aggfunc=\"first\",\n",
    "        dropna=False,\n",
    "    )\n",
    "    newdf.index.name = None\n",
    "    if not os.path.exists(substitute_data_abspath):\n",
    "        os.makedirs(substitute_data_abspath)\n",
    "    if outlier_mode:\n",
    "        data_name = os.path.join(substitute_data_abspath, \"MachineLabelsRefine.h5\")\n",
    "        tracked_hdf = os.path.join(\n",
    "            substitute_data_abspath, (\"MachineLabelsRefine_\" + \".h5\")\n",
    "        )\n",
    "    else:\n",
    "        data_name = os.path.join(\n",
    "            substitute_data_abspath,\n",
    "            (\"CollectedData_\" + self._config[\"experimenter\"] + \".h5\"),\n",
    "        )\n",
    "        tracked_hdf = os.path.join(\n",
    "            substitute_data_abspath,\n",
    "            (\"CollectedData_\" + self._config[\"experimenter\"] + \".h5\"),\n",
    "        )\n",
    "    newdf.to_hdf(data_name, \"df_with_missing\", format=\"table\", mode=\"w\")\n",
    "    newdf.to_hdf(tracked_hdf, \"df_with_missing\", format=\"table\", mode=\"w\")\n",
    "    tracked_csv = data_name.split(\".h5\")[0] + \".csv\"\n",
    "    newdf.to_csv(tracked_csv, na_rep=\"NaN\")\n",
    "    print(\n",
    "        \"Successfully spliced XMALab 2D points to DLC format\",\n",
    "        \"saved \" + str(data_name),\n",
    "        \"saved \" + str(tracked_hdf),\n",
    "        \"saved \" + str(tracked_csv),\n",
    "        sep=\"\\n\",\n",
    "    )\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def imagej_auto_contrast(img, saturated=0.35):\n",
    "    \"\"\"\n",
    "    Emulates ImageJ Auto-Adjust Brightness/Contrast.\n",
    "    img: grayscale, numpy array (uint8 or uint16)\n",
    "    saturated: percentage of pixels to clip at each end (default 0.35%)\n",
    "    Returns contrast-stretched uint8 image.\n",
    "    \"\"\"\n",
    "    img = img.astype(np.float32)\n",
    "    low, high = np.percentile(img, (saturated, 100.0 - saturated))\n",
    "    if high - low < 1e-3:\n",
    "        stretched = np.clip(img, 0, 255)\n",
    "    else:\n",
    "        stretched = (img - low) * 255.0 / (high - low)\n",
    "        stretched = np.clip(stretched, 0, 255)\n",
    "    return stretched.astype(np.uint8)\n",
    "\n",
    "def merge_avi_to_rgb(avi1, avi2, out_path, mode=\"difference\", saturated=0.35, codec=\"XVID\", fps=None):\n",
    "    cap1 = cv2.VideoCapture(avi1)\n",
    "    cap2 = cv2.VideoCapture(avi2)\n",
    "    w = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    if fps is None:\n",
    "        fps = cap1.get(cv2.CAP_PROP_FPS) or 30\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "    out = cv2.VideoWriter(out_path, fourcc, fps, (w, h))\n",
    "\n",
    "    frame_num = 0\n",
    "    while True:\n",
    "        ret1, frame1 = cap1.read()\n",
    "        ret2, frame2 = cap2.read()\n",
    "        if not (ret1 and ret2):\n",
    "            break\n",
    "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "        # --- Apply ImageJ auto contrast normalization ---\n",
    "        norm1 = imagej_auto_contrast(gray1, saturated)\n",
    "        norm2 = imagej_auto_contrast(gray2, saturated)\n",
    "        # Use normalized frames for blue channel and output\n",
    "        if mode == \"difference\":\n",
    "            blue = cv2.absdiff(norm1, norm2)\n",
    "        elif mode == \"multiply\":\n",
    "            blue = ((norm1.astype(np.uint16) * norm2.astype(np.uint16)) // 255).astype(np.uint8)\n",
    "        else:\n",
    "            blue = np.zeros_like(norm1, dtype=np.uint8)\n",
    "        merged = cv2.merge([blue, norm2, norm1])   # OpenCV expects BGR image order\n",
    "        out.write(merged)\n",
    "        frame_num += 1\n",
    "        if frame_num % 50 == 0:\n",
    "            print(f\"Processed {frame_num} frames\", end='\\r')\n",
    "    cap1.release()\n",
    "    cap2.release()\n",
    "    out.release()\n",
    "    print(f\"\\nRGB video created: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc99374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "avi1 = r\"F:\\In Vivo XROMM EMG\\28MAY2025\\Trials AVIs\\28MAY2025_raisin_trial4_rat101_C001H001S0001.avi\"\n",
    "avi2 = r\"F:\\In Vivo XROMM EMG\\28MAY2025\\Trials AVIs\\28MAY2025_raisin_trial4_rat101_C002H001S0001.avi\"\n",
    "out_video = r'F:\\In Vivo XROMM EMG\\28MAY2025\\28MAY2025_raisin_trial4_rat101_RGB_output2.avi'\n",
    "merge_avi_to_rgb(avi1, avi2, out_video, mode=\"difference\", saturated=0.35, codec=\"MJPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4953d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader1 = iio.imiter(r\"F:\\In Vivo XROMM EMG\\28MAY2025\\Trials AVIs\\28MAY2025_almond_trial21_rat101_C001H001S0001.avi\")  # your actual files\n",
    "reader2 = iio.imiter(r\"F:\\In Vivo XROMM EMG\\28MAY2025\\Trials AVIs\\28MAY2025_almond_trial21_rat101_C002H001S0001.avi\")\n",
    "writer = imageio.get_writer(r'F:\\In Vivo XROMM EMG\\28MAY2025\\28MAY2025_almond_trial21_rat101_RGB_output2.avi', fps=30)\n",
    "\n",
    "for f1, f2 in zip(reader1, reader2):\n",
    "    \n",
    "    f1_gray = (0.114*f1[:,:,0] + 0.587*f1[:,:,1] + 0.299*f1[:,:,2]).astype(np.uint8)\n",
    "    f1_gray = imagej_auto_contrast(f1_gray, 0.35)\n",
    "    f2_gray = (0.114*f2[:,:,0] + 0.587*f2[:,:,1] + 0.299*f2[:,:,2]).astype(np.uint8)\n",
    "    f2_gray =  imagej_auto_contrast(f2_gray, 0.35)\n",
    "    blue = np.abs(f1_gray.astype(np.int16) - f2_gray.astype(np.int16)).astype(np.uint8)\n",
    "    merged = np.stack([blue, f2_gray, f1_gray], axis=2)\n",
    "    writer.append_data(merged)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4656c9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "video1_path = r\"F:\\In Vivo XROMM EMG\\28MAY2025\\28MAY2025_raisin_trial4_rat101_C001H001S0001.avi\"\n",
    "video2_path = r\"F:\\In Vivo XROMM EMG\\28MAY2025\\28MAY2025_raisin_trial4_rat101_C002H001S0001.avi\"\n",
    "output_path = r'F:\\In Vivo XROMM EMG\\28MAY2025\\Composite Videos\\28MAY2025_raisin_trial4_rat101_cams1and2.avi'\n",
    "\n",
    "reader1 = imageio.get_reader(video1_path)\n",
    "reader2 = imageio.get_reader(video2_path)\n",
    "meta1 = reader1.get_meta_data()\n",
    "meta2 = reader2.get_meta_data()\n",
    "fps = meta1['fps']  # Or min(meta1['fps'], meta2['fps'])\n",
    "\n",
    "# Find the smallest number of frames\n",
    "nframes = min(meta1['nframes'], meta2['nframes'])\n",
    "\n",
    "# Determine output size (pad heights if needed)\n",
    "height = max(meta1['size'][1], meta2['size'][1])\n",
    "width = meta1['size'][0] + meta2['size'][0]\n",
    "\n",
    "def pad_to_height(frame, height):\n",
    "    if frame.shape[0] == height:\n",
    "        return frame\n",
    "    pad = height - frame.shape[0]\n",
    "    top = pad // 2\n",
    "    bot = pad - top\n",
    "    return np.pad(frame, ((top, bot), (0,0), (0,0)), mode='constant')\n",
    "\n",
    "writer = imageio.get_writer(output_path, fps=fps)\n",
    "\n",
    "for i, (f1, f2) in enumerate(zip(reader1, reader2)):\n",
    "    if i >= nframes:\n",
    "        break\n",
    "    # Pad if necessary\n",
    "    f1 = pad_to_height(f1, height)\n",
    "    f2 = pad_to_height(f2, height)\n",
    "    # Concatenate along width axis (side by side)\n",
    "    merged = np.concatenate((f1, f2), axis=1)\n",
    "    writer.append_data(merged)\n",
    "    if i % 50 == 0:\n",
    "        print(f'Processed frame {i}', end='\\r')\n",
    "\n",
    "reader1.close()\n",
    "reader2.close()\n",
    "writer.close()\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a0abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(r'D:\\XROMM DLC Networks')\n",
    "\n",
    "task = \"108_Feeding_RGB\" # Enter the name of your experiment Task\n",
    "experimenter = \"Brocklehurst\" # Enter the name of the experimenter\n",
    "video = [\n",
    "    r\"F:\\In vivo XROMM\\28OCT24\\Trials\\28OCT24_trial1_rat108_raisin_rgb.avi\",\n",
    "    r\"F:\\In vivo XROMM\\28OCT24\\Trials\\28OCT24_trial3_rat108_raisin_rgb.avi\",\n",
    "    r\"F:\\In vivo XROMM\\29OCT24\\Trials\\29OCT24_rat108_trial1_brazil_rgb.avi\",\n",
    "    r\"F:\\In vivo XROMM\\29OCT24\\Trials\\29OCT24_rat108_trial2_brazil_rgb.avi\"\n",
    "] # Enter the paths of your videos OR FOLDER you want to grab frames from.\n",
    "\n",
    "path_config_file = deeplabcut.create_new_project(\n",
    "    task,\n",
    "    experimenter,\n",
    "    video,\n",
    "    copy_videos=True,\n",
    ")\n",
    "\n",
    "# NOTE: The function returns the path, where your project is. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d328005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marker001_cam1',\n",
       " 'marker001_cam2',\n",
       " 'marker002_cam1',\n",
       " 'marker002_cam2',\n",
       " 'marker003_cam1',\n",
       " 'marker003_cam2',\n",
       " 'marker004_cam1',\n",
       " 'marker004_cam2',\n",
       " 'marker005_cam1',\n",
       " 'marker005_cam2',\n",
       " 'marker006_cam1',\n",
       " 'marker006_cam2',\n",
       " 'marker007_cam1',\n",
       " 'marker007_cam2',\n",
       " 'marker008_cam1',\n",
       " 'marker008_cam2',\n",
       " 'marker009_cam1',\n",
       " 'marker009_cam2',\n",
       " 'marker010_cam1',\n",
       " 'marker010_cam2',\n",
       " 'marker011_cam1',\n",
       " 'marker011_cam2',\n",
       " 'marker012_cam1',\n",
       " 'marker012_cam2',\n",
       " 'marker013_cam1',\n",
       " 'marker013_cam2',\n",
       " 'marker014_cam1',\n",
       " 'marker014_cam2',\n",
       " 'marker015_cam1',\n",
       " 'marker015_cam2',\n",
       " 'marker016_cam1',\n",
       " 'marker016_cam2',\n",
       " 'marker017_cam1',\n",
       " 'marker017_cam2',\n",
       " 'marker018_cam1',\n",
       " 'marker018_cam2',\n",
       " 'marker019_cam1',\n",
       " 'marker019_cam2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bodyparts_from_xma(r\"D:\\XROMM Trial Images\\28OCT24\\28OCT24_rat108_Trial01_2D_Points.csv\", mode = 'rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8310f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'D:\\XROMM DLC Networks')\n",
    "# You could also enter this manually (e.g. if the project is already created and you want to pick up, where you stopped...)\n",
    "# Enter the path of the config file that was just created from the above step (check the folder):\n",
    "path_config_file = r\"D:\\XROMM DLC Networks\\108_Feeding_RGB-Brocklehurst-2025-09-09\\config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f9b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#AUTOMATIC:\n",
    "deeplabcut.extract_frames(path_config_file, algo='kmeans', userfeedback=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262cc4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def xma_to_dlc(path_config_file,data_path,dataset_name,scorer,nframes,nnetworks = 1):\n",
    "config = path_config_file[:-12]\n",
    "scorer = 'Brocklehurst'\n",
    "\n",
    "#trialnames = [folder for folder in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, folder)) and not folder.startswith('.')]\n",
    "\n",
    "### PART 1: Pick frames for dataset\n",
    "#contents = os.listdir(data_path+\"/\"+trial)\n",
    "#filename = [x for x in contents if \".csv\" in x] # csv filename\n",
    "TrialNames = ['29OCT24_rat108_trial1_brazil', '29OCT24_rat108_trial2_brazil', '28OCT24_trial1_rat108_raisin', '28OCT24_trial3_rat108_raisin']\n",
    "TrialFolderNames = [x + '_rgb' for x in TrialNames]\n",
    "\n",
    "for TrialName, TrialFolderName in zip(TrialNames, TrialFolderNames):\n",
    "\n",
    "    df1 = pd.read_csv(os.path.join(config, 'labeled-data', TrialFolderName, TrialName + '_2D_Points.csv'))\n",
    "\n",
    "    # read pointnames from header row\n",
    "    pointnames = df1.columns[::2].astype(str).str[:-2].tolist()\n",
    "    #pnames.append(pointnames)\n",
    "\n",
    "    #if pointnames aren't the same across trials\n",
    "    #if any(pnames[0] != x for x in pnames):\n",
    "    #    raise ValueError('Make sure point names are consistent across trials')\n",
    "\n",
    "    ### Part 2: Extract images and 2D point data\n",
    "\n",
    "    relnames = []\n",
    "    data = pd.DataFrame()\n",
    "    # new training dataset folder\n",
    "    newpath = os.path.join(config, 'labeled-data', TrialFolderName)\n",
    "    h5_save_path = newpath+\"/CollectedData_\"+scorer+\".h5\"\n",
    "    csv_save_path = newpath+\"/CollectedData_\"+scorer+\".csv\"\n",
    "\n",
    "    relpath = os.path.join('labeled-data', TrialFolderName)\n",
    "\n",
    "    img_list = list(pathlib.Path(newpath).glob('*.png'))\n",
    "\n",
    "    img_numbers = []\n",
    "\n",
    "    for i in img_list:\n",
    "        relname = os.path.join(relpath, os.path.basename(i))\n",
    "        relnames = relnames + [relname]\n",
    "        \n",
    "        img_name = os.path.basename(i)\n",
    "        img_number = int(re.findall(r'\\d+', img_name)[0])\n",
    "        img_number = img_number\n",
    "        img_numbers.append(img_number)\n",
    "\n",
    "    # extract 2D points data\n",
    "    #df1= dfs[trialnum]\n",
    "    xpos1 = df1.iloc[img_numbers,0+(1-1)*2::4]\n",
    "    ypos1 = df1.iloc[img_numbers,1+(1-1)*2::4]\n",
    "\n",
    "    xpos2 = df1.iloc[img_numbers,0+(2-1)*2::4]\n",
    "    #xpos2 += 1024\n",
    "    ypos2 = df1.iloc[img_numbers,1+(2-1)*2::4]\n",
    "\n",
    "    temp_data1 = pd.concat([xpos1,ypos1,xpos2,ypos2],axis=1).sort_index(axis=1)\n",
    "    temp_data1.columns = range(temp_data1.shape[1])\n",
    "    data = pd.concat([data,temp_data1])\n",
    "\n",
    "\n",
    "    ### Part 3: Complete final structure of datafiles\n",
    "    dataFrame = pd.DataFrame()\n",
    "    temp = np.empty((data.shape[0],2,))\n",
    "    temp[:] = np.nan\n",
    "    for i,bodypart in enumerate(pointnames):\n",
    "        index = pd.MultiIndex.from_product([[scorer], [bodypart], ['x', 'y']],names=['scorer', 'bodyparts', 'coords'])\n",
    "        frame = pd.DataFrame(temp, columns = index, index = relnames)\n",
    "        frame.iloc[:,0:2] = data.iloc[:, 2*i:2*i+2].values.astype(float)\n",
    "        dataFrame = pd.concat([dataFrame, frame],axis=1)\n",
    "    dataFrame.replace('', np.nan, inplace=True)\n",
    "    dataFrame.replace(' NaN', np.nan, inplace=True)\n",
    "    dataFrame.replace(' NaN ', np.nan, inplace=True)\n",
    "    dataFrame.replace('NaN ', np.nan, inplace=True)\n",
    "    dataFrame.apply(pd.to_numeric)\n",
    "    dataFrame.to_hdf(h5_save_path, key=\"df_with_missing\", mode=\"w\")\n",
    "    dataFrame.to_csv(csv_save_path,na_rep='NaN')\n",
    "    print(\"...done.\")\n",
    "\n",
    "print(\"Training data extracted to projectpath/labeled-data. Now use deeplabcut.create_training_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bba79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.check_labels(path_config_file, draw_skeleton = False) # this creates a subdirectory with the frames + your labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea21550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623b3b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.train_network(\n",
    "    path_config_file,\n",
    "    shuffle=1,\n",
    "    trainingsetindex=0,\n",
    "    device=\"cuda:0\",\n",
    "    max_snapshots_to_keep=5,\n",
    "    displayiters=10,\n",
    "    save_epochs=5,\n",
    "    epochs=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336043e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.evaluate_network(path_config_file, Shuffles=[1], plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b29d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "camdata_dir = r\"D:\\XROMM DLC Networks\\108_Feeding_RGB-Brocklehurst-2025-09-09\\videos-for-analysis\"\n",
    "videos_2_analyse = glob.glob(camdata_dir + '/*.avi')\n",
    "\n",
    "deeplabcut.analyze_videos(\n",
    "    path_config_file, \n",
    "    videos_2_analyse,\n",
    "    device=\"cuda:0\",\n",
    "    save_as_csv=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b3b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "camdata_dir = r\"D:\\XROMM DLC Networks\\108_Feeding_RGB-Brocklehurst-2025-09-09\\videos-for-analysis\"\n",
    "DLC_outs = glob.glob(camdata_dir + '/*DLC*.csv')\n",
    "\n",
    "for i in  DLC_outs:\n",
    "    camdata_file_base = os.path.basename(i)\n",
    "    camdata_file_name = camdata_file_base.split('DLC')[0] + 'Predicted-Points-2D.csv'\n",
    "\n",
    "    camdata = pd.read_csv(i, sep=',',header=None)\n",
    "    pointnames = list(camdata.loc[1,1:].unique())\n",
    "\n",
    "    # reformat CSV / get rid of headers\n",
    "    camdata = camdata.loc[3:,1:]\n",
    "    camdata.columns = range(camdata.shape[1])\n",
    "    camdata.index = range(camdata.shape[0])\n",
    "\n",
    "    # make new column names\n",
    "    nvar = len(pointnames)\n",
    "    pointnames = [item for item in pointnames for repetitions in range(2)]\n",
    "    post = [\"_X\", \"_Y\"]*nvar\n",
    "    cols = [m+str(n) for m,n in zip(pointnames,post)]\n",
    "\n",
    "    # remove likelihood columns\n",
    "    camdata = camdata.drop(camdata.columns[2::3],axis=1)\n",
    "    camdata = camdata.astype('float')\n",
    "    # replace col names with new indices\n",
    "\n",
    "    c1dataX = camdata.iloc[:, ::4]\n",
    "    #c1dataX[c1dataX > 1024] = c1dataX[c1dataX > 1024] - 1024    \n",
    "    c1dataY = camdata.iloc[:, 1::4]\n",
    "    c2dataX = camdata.iloc[:, 2::4]\n",
    "    #c2dataX[c2dataX < 1024] = c2dataX[c2dataX < 1024] + 1024    \n",
    "    #c2dataX = c2dataX.sub(1024)\n",
    "    c2dataY = camdata.iloc[:, 3::4]\n",
    "\n",
    "    data_all = (pd.concat([c1dataX, c1dataY, c2dataX, c2dataY],axis=1).sort_index(axis=1))\n",
    "    data_all.columns = cols\n",
    "    data_all[data_all < 0] = 1\n",
    "    #data_all.to_hdf(h5_save_path, key=\"df_with_missing\", mode=\"w\")\n",
    "    data_all.to_csv(camdata_dir + '/' + camdata_file_name,na_rep='NaN',index=False)\n",
    "    #c2cols = list(range(2,camdata.shape[1],4)) + list(range(3,camdata.shape[1],4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6896d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "camdata_dir = r\"D:\\XROMM DLC Networks\\108_Feeding_RGB-Brocklehurst-2025-09-09\\videos-for-analysis\"\n",
    "videos_2_analyse = glob.glob(camdata_dir + '/*.avi')\n",
    "\n",
    "deeplabcut.extract_outlier_frames(path_config_file, videos_2_analyse[0], automatic = True, outlieralgorithm=\"uncertain\", p_bound  = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD XMA TO DLC CODE CHUNK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9d73bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.merge_datasets(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5f8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ef17ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h5_save_path = savepath+\"/\"+trialname+\"-Predicted2DPoints.h5\"\n",
    "#csv_save_path = savepath+\"/\"+trialname+\"-Predicted2DPoints.csv\"\n",
    "\n",
    "cam12data = pd.read_csv(cam12data_file, sep=',',header=None)\n",
    "pointnames = list(cam12data.loc[1,1:].unique())\n",
    "\n",
    "# reformat CSV / get rid of headers\n",
    "cam12data = cam12data.loc[3:,1:]\n",
    "cam12data.columns = range(cam12data.shape[1])\n",
    "cam12data.index = range(cam12data.shape[0])\n",
    "\n",
    "# make new column names\n",
    "nvar = len(pointnames)\n",
    "pointnames = [item for item in pointnames for repetitions in range(2)]\n",
    "post = [\"_X\", \"_Y\"]*nvar\n",
    "cols = [m+str(n) for m,n in zip(pointnames,post)]\n",
    "\n",
    " # remove likelihood columns\n",
    "cam12data = cam12data.drop(cam12data.columns[2::3],axis=1)\n",
    "cam12data = cam12data.astype('float32')\n",
    "# replace col names with new indices\n",
    "\n",
    "c1dataX = cam12data.iloc[:, ::4]\n",
    "c1dataY = cam12data.iloc[:, 1::4]\n",
    "c2dataX = cam12data.iloc[:, 2::4]\n",
    "c2dataX = c2dataX.sub(1024)\n",
    "c2dataY = cam12data.iloc[:, 3::4]\n",
    "\n",
    "data_all = (pd.concat([c1dataX, c1dataY, c2dataX, c2dataY],axis=1).sort_index(axis=1))\n",
    "data_all.columns = cols\n",
    "data_all[data_all < 0] = 1\n",
    "#data_all.to_hdf(h5_save_path, key=\"df_with_missing\", mode=\"w\")\n",
    "data_all.to_csv('28MAY2025_raisin_trial4_rat101_cams1and2_Predicted-Points.csv',na_rep='NaN',index=False)\n",
    "#c2cols = list(range(2,cam12data.shape[1],4)) + list(range(3,cam12data.shape[1],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "   \n",
    "\n",
    "    # replace col names with new indices\n",
    "    c1cols = list(range(0,cam12data.shape[1]*2,4)) + list(range(0,1 + cam12data.shape[1]*2,4))\n",
    "    c2cols = list(range(2,cam12data.shape[1]*2,4)) + list(range(3,cam12data.shape[1]*2,4))\n",
    "    c1cols.sort()\n",
    "    c2cols.sort()\n",
    "    cam1data.columns = c1cols\n",
    "    cam2data.columns = c2cols\n",
    "\n",
    "    df = pd.concat([cam1data,cam2data],axis=1).sort_index(axis=1)\n",
    "    df.columns = cols\n",
    "    df.to_hdf(h5_save_path, key=\"df_with_missing\", mode=\"w\")\n",
    "    df.to_csv(csv_save_path,na_rep='NaN',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa29437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd071640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6dd16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da7230",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "deeplabcut.check_labels(path_config_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEPLABCUT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
