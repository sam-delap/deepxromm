{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import deeplabcut\n",
    "from deeplabcut.utils import xrommtools\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ruamel.yaml import YAML\n",
    "working_dir=os.getcwd()\n",
    "experimenter='SD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"C:\\Users\\Samuel_DeLap.UMLADCO\\Documents\\DeLap\\XMA2DLC_Pipeline\\Code\\Code-SD-2022-11-18\\videos\"\n",
      "Created \"C:\\Users\\Samuel_DeLap.UMLADCO\\Documents\\DeLap\\XMA2DLC_Pipeline\\Code\\Code-SD-2022-11-18\\labeled-data\"\n",
      "Created \"C:\\Users\\Samuel_DeLap.UMLADCO\\Documents\\DeLap\\XMA2DLC_Pipeline\\Code\\Code-SD-2022-11-18\\training-datasets\"\n",
      "Created \"C:\\Users\\Samuel_DeLap.UMLADCO\\Documents\\DeLap\\XMA2DLC_Pipeline\\Code\\Code-SD-2022-11-18\\dlc-models\"\n",
      "Copying the videos\n",
      "C:\\Users\\Samuel_DeLap.UMLADCO\\Documents\\DeLap\\XMA2DLC_Pipeline\\Code\\Code-SD-2022-11-18\\videos\\dummy.avi\n",
      "Generated \"C:\\Users\\Samuel_DeLap.UMLADCO\\Documents\\DeLap\\XMA2DLC_Pipeline\\Code\\Code-SD-2022-11-18\\config.yaml\"\n",
      "\n",
      "A new project with name Code-SD-2022-11-18 is created at C:\\Users\\Samuel_DeLap.UMLADCO\\Documents\\DeLap\\XMA2DLC_Pipeline\\Code and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    }
   ],
   "source": [
    "# samtools.create_new_project(working_dir, experimenter)\n",
    "dirs = [\"trainingdata\", \"trials\", \"XMA_files\"]\n",
    "for dir in dirs:\n",
    "    try:\n",
    "        os.mkdir(dir)\n",
    "    except FileExistsError:\n",
    "        continue\n",
    "\n",
    "config = open(\"project_config.yaml\", 'w')\n",
    "\n",
    "# Create a fake video to pass into the deeplabcut workflow\n",
    "frame = np.zeros((480, 480, 3), np.uint8)\n",
    "out = cv2.VideoWriter('dummy.avi',cv2.VideoWriter_fourcc(*'DIVX'), 15, (480,480))\n",
    "out.write(frame)\n",
    "out.release()\n",
    "\n",
    "# Create a new project\n",
    "yaml = YAML()\n",
    "task = working_dir.split(\"\\\\\")[len(working_dir.split(\"\\\\\")) - 1]\n",
    "path_config_file = deeplabcut.create_new_project(task, experimenter, [working_dir + \"\\\\dummy.avi\"], working_dir + \"\\\\\", copy_videos=True)\n",
    "template = f\"\"\"\n",
    "task: {task}\n",
    "experimenter: {experimenter}\n",
    "working_dir: {working_dir}\n",
    "path_config_file: {path_config_file}\n",
    "dataset_name: \n",
    "nframes:\n",
    "\"\"\"\n",
    "\n",
    "tmp = yaml.load(template)\n",
    "\n",
    "yaml.dump(tmp, config)\n",
    "config.close()\n",
    "\n",
    "try:\n",
    "    os.rmdir(path_config_file[:path_config_file.find(\"config\")] + \"labeled-data\\\\dummy\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.remove(path_config_file[:path_config_file.find(\"config\")] + \"\\\\videos\\\\dummy.avi\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.remove(\"dummy.avi\")\n",
    "except FileNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting camera 1 trial images and 2D points...\n",
      "Extracting camera 2 trial images and 2D points...\n",
      "...done.\n",
      "Training data extracted to projectpath/labeled-data. Now use deeplabcut.create_training_dataset\n",
      "C:\\Users\\Samuel_DeLap.UMLADCO\\Documents\\DeLap\\XMA2DLC_Pipeline\\Code\\Code-SD-2022-11-18\\labeled-data\\dummy\\CollectedData_SD.h5  not found (perhaps not annotated).\n",
      "Annotation data was not found by splitting video paths (from config['video_sets']). An alternative route is taken...\n",
      "The following folders were found: ['C:\\\\Users\\\\Samuel_DeLap.UMLADCO\\\\Documents\\\\DeLap\\\\XMA2DLC_Pipeline\\\\Code\\\\Code-SD-2022-11-18\\\\labeled-data\\\\JohnnyAppleseed']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12],\n",
      "                [13],\n",
      "                [14],\n",
      "                [15],\n",
      "                [16],\n",
      "                [17],\n",
      "                [18],\n",
      "                [19],\n",
      "                [20],\n",
      "                [21],\n",
      "                [22],\n",
      "                [23]],\n",
      " 'all_joints_names': ['F1',\n",
      "                      'F2',\n",
      "                      'LJla',\n",
      "                      'LJlm',\n",
      "                      'LJlc',\n",
      "                      'GHa',\n",
      "                      'TP',\n",
      "                      'GHc',\n",
      "                      'PMX',\n",
      "                      'AMd',\n",
      "                      'AMv',\n",
      "                      'SQr',\n",
      "                      'SQl',\n",
      "                      'DMd',\n",
      "                      'DMv',\n",
      "                      'BHa',\n",
      "                      'BHc',\n",
      "                      'SHa',\n",
      "                      'SHc',\n",
      "                      'CL',\n",
      "                      'HPa',\n",
      "                      'HPc',\n",
      "                      'EPc',\n",
      "                      'EPa'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 1,\n",
      " 'clahe': True,\n",
      " 'claheratio': 0.1,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_CodeNov18\\\\Code_SD95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'edge': False,\n",
      " 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]},\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'histeq': True,\n",
      " 'histeqratio': 0.1,\n",
      " 'init_weights': 'c:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\DEEPLABCUT\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_CodeNov18\\\\Documentation_data-Code_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 24,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\Samuel_DeLap.UMLADCO\\\\Documents\\\\DeLap\\\\XMA2DLC_Pipeline\\\\Code\\\\Code-SD-2022-11-18',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'sharpen': False,\n",
      " 'sharpenratio': 0.3,\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Samuel_DeLap.UMLADCO\\\\Documents\\\\DeLap\\\\XMA2DLC_Pipeline\\\\Code\\\\Code-SD-2022-11-18\\\\dlc-models\\\\iteration-0\\\\CodeNov18-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n",
      "Selecting single-animal trainer\n",
      "Batch Size is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ImageNet-pretrained resnet_50\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\\\\Users\\\\Samuel_DeLap.UMLADCO\\\\Documents\\\\DeLap\\\\XMA2DLC_Pipeline\\\\Code\\\\Code-SD-2022-11-18\\\\dlc-models\\\\iteration-0\\\\CodeNov18-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23]], 'all_joints_names': ['F1', 'F2', 'LJla', 'LJlm', 'LJlc', 'GHa', 'TP', 'GHc', 'PMX', 'AMd', 'AMv', 'SQr', 'SQl', 'DMd', 'DMv', 'BHa', 'BHc', 'SHa', 'SHc', 'CL', 'HPa', 'HPc', 'EPc', 'EPa'], 'alpha_r': 0.02, 'apply_prob': 0.5, 'clahe': True, 'claheratio': 0.1, 'cropratio': 0.4, 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_CodeNov18\\\\Code_SD95shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]}, 'histeq': True, 'histeqratio': 0.1, 'init_weights': 'c:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\DEEPLABCUT\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_CodeNov18\\\\Documentation_data-Code_95shuffle1.pickle', 'min_input_size': 64, 'multi_stage': False, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 24, 'pos_dist_thresh': 17, 'project_path': 'C:\\\\Users\\\\Samuel_DeLap.UMLADCO\\\\Documents\\\\DeLap\\\\XMA2DLC_Pipeline\\\\Code\\\\Code-SD-2022-11-18', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'sharpen': False, 'sharpenratio': 0.3, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n",
      "Starting training....\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Samuel_DeLap.UMLADCO\\Documents\\DeLap\\XMA2DLC_Pipeline\\Code\\samtest.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samuel_DeLap.UMLADCO/Documents/DeLap/XMA2DLC_Pipeline/Code/samtest.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Samuel_DeLap.UMLADCO/Documents/DeLap/XMA2DLC_Pipeline/Code/samtest.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m deeplabcut\u001b[39m.\u001b[39mcreate_training_dataset(path_config_file)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Samuel_DeLap.UMLADCO/Documents/DeLap/XMA2DLC_Pipeline/Code/samtest.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m deeplabcut\u001b[39m.\u001b[39;49mtrain_network(path_config_file)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py:218\u001b[0m, in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[0;32m    207\u001b[0m         train(\n\u001b[0;32m    208\u001b[0m             \u001b[39mstr\u001b[39m(poseconfigfile),\n\u001b[0;32m    209\u001b[0m             displayiters,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m             allow_growth\u001b[39m=\u001b[39mallow_growth,\n\u001b[0;32m    215\u001b[0m         )  \u001b[39m# pass on path and file name for pose_cfg.yaml!\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 218\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    219\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     os\u001b[39m.\u001b[39mchdir(\u001b[39mstr\u001b[39m(start_path))\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py:207\u001b[0m, in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mdeeplabcut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpose_estimation_tensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrain\u001b[39;00m \u001b[39mimport\u001b[39;00m train\n\u001b[0;32m    206\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSelecting single-animal trainer\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 207\u001b[0m         train(\n\u001b[0;32m    208\u001b[0m             \u001b[39mstr\u001b[39;49m(poseconfigfile),\n\u001b[0;32m    209\u001b[0m             displayiters,\n\u001b[0;32m    210\u001b[0m             saveiters,\n\u001b[0;32m    211\u001b[0m             maxiters,\n\u001b[0;32m    212\u001b[0m             max_to_keep\u001b[39m=\u001b[39;49mmax_snapshots_to_keep,\n\u001b[0;32m    213\u001b[0m             keepdeconvweights\u001b[39m=\u001b[39;49mkeepdeconvweights,\n\u001b[0;32m    214\u001b[0m             allow_growth\u001b[39m=\u001b[39;49mallow_growth,\n\u001b[0;32m    215\u001b[0m         )  \u001b[39m# pass on path and file name for pose_cfg.yaml!\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\train.py:272\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[0;32m    269\u001b[0m     current_lr \u001b[39m=\u001b[39m lr_gen\u001b[39m.\u001b[39mget_lr(it \u001b[39m-\u001b[39m start_iter)\n\u001b[0;32m    270\u001b[0m     lr_dict \u001b[39m=\u001b[39m {learning_rate: current_lr}\n\u001b[1;32m--> 272\u001b[0m [_, loss_val, summary] \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m    273\u001b[0m     [train_op, total_loss, merged_summaries], feed_dict\u001b[39m=\u001b[39;49mlr_dict\n\u001b[0;32m    274\u001b[0m )\n\u001b[0;32m    275\u001b[0m cum_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_val\n\u001b[0;32m    276\u001b[0m train_writer\u001b[39m.\u001b[39madd_summary(summary, it)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py:967\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    964\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    966\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 967\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[0;32m    968\u001b[0m                      run_metadata_ptr)\n\u001b[0;32m    969\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[0;32m    970\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1190\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[39mif\u001b[39;00m final_fetches \u001b[39mor\u001b[39;00m final_targets \u001b[39mor\u001b[39;00m (handle \u001b[39mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1190\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_run(handle, final_targets, final_fetches,\n\u001b[0;32m   1191\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1192\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1193\u001b[0m   results \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1370\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1367\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[0;32m   1369\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1370\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m   1371\u001b[0m                        run_metadata)\n\u001b[0;32m   1372\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1373\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1377\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_call\u001b[39m(\u001b[39mself\u001b[39m, fn, \u001b[39m*\u001b[39margs):\n\u001b[0;32m   1376\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m   1378\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1379\u001b[0m     message \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_text(e\u001b[39m.\u001b[39mmessage)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1360\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[0;32m   1358\u001b[0m   \u001b[39m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[0;32m   1359\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_graph()\n\u001b[1;32m-> 1360\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m   1361\u001b[0m                                   target_list, run_metadata)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1453\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_tf_sessionrun\u001b[39m(\u001b[39mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1452\u001b[0m                         run_metadata):\n\u001b[1;32m-> 1453\u001b[0m   \u001b[39mreturn\u001b[39;00m tf_session\u001b[39m.\u001b[39;49mTF_SessionRun_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session, options, feed_dict,\n\u001b[0;32m   1454\u001b[0m                                           fetch_list, target_list,\n\u001b[0;32m   1455\u001b[0m                                           run_metadata)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# samtools.train_network(working_dir)\n",
    "config_file = open(working_dir + \"\\\\project_config.yaml\", 'r')\n",
    "yaml = YAML()\n",
    "project = yaml.load(config_file)\n",
    "\n",
    "# Establish project vars\n",
    "path_config_file = project['path_config_file']\n",
    "data_path = working_dir + \"\\\\trainingdata\"\n",
    "dataset_name = project['dataset_name']\n",
    "experimenter = str(project['experimenter'])\n",
    "nframes = project['nframes']\n",
    "\n",
    "if dataset_name is None:\n",
    "    raise Exception(\"Please specify a name for this dataset in the config file\")\n",
    "if nframes is None:\n",
    "    raise Exception(\"Please specify the number of frames in the training dataset\")\n",
    "\n",
    "try:\n",
    "    xrommtools.xma_to_dlc(path_config_file, data_path, dataset_name, experimenter, nframes)\n",
    "except UnboundLocalError:\n",
    "    pass\n",
    "deeplabcut.create_training_dataset(path_config_file)\n",
    "deeplabcut.train_network(path_config_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('DEEPLABCUT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e36de33ca1db2a4c7c861a8ae7e801109fa08548f38c8df6290b14541cc31ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
